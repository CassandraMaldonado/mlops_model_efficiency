{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4224577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import types\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.quantization as tq\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models as torchvision_models\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e34512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS for FP32 training.\n",
      "Using CPU for quantization operations.\n",
      "Using qnnpack backend.\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# Settings\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device_train = torch.device('mps')\n",
    "    print(f\"Using MPS for FP32 training.\")\n",
    "else:\n",
    "    device_train = torch.device('cpu')\n",
    "    print(f\"Using CPU for training.\")\n",
    "\n",
    "# CPU for quantization operations.\n",
    "device_quant = torch.device('cpu')\n",
    "print(f\"Using CPU for quantization operations.\")\n",
    "\n",
    "# Quantization backend to qnnpack.\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "print(f\"Using qnnpack backend.\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS_BASELINE = 10  \n",
    "EPOCHS_QAT = 3       \n",
    "EPOCHS_KD = 3\n",
    "PRINT_FREQ = 100\n",
    "\n",
    "os.makedirs('./quantization_results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c9d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 50000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# Data: CIFAR-10\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -----------------------------------------------------\n",
    "# Model\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "# ResNet18 configured for CIFAR-10.\n",
    "def get_resnet18(num_classes=10, pretrained=False):\n",
    "    model = torchvision_models.resnet18(weights=None)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    prepare_residual_blocks_for_quant(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Quantization stubs.\n",
    "class QuantStubWrapper(nn.Module):\n",
    "    def __init__(self, module: nn.Module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.quant = tq.QuantStub()\n",
    "        self.dequant = tq.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.module(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Making sure the model exposes Quant/DeQuant stubs exactly once.\n",
    "def wrap_with_quant_stubs(model: nn.Module) -> nn.Module:\n",
    "    if isinstance(model, QuantStubWrapper):\n",
    "        return model\n",
    "    return QuantStubWrapper(model)\n",
    "\n",
    "\n",
    "def _basicblock_forward_quant(self, x):\n",
    "    identity = x\n",
    "\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "\n",
    "    if self.downsample is not None:\n",
    "        identity = self.downsample(x)\n",
    "\n",
    "    out = self.skip_add.add(out, identity)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Prepare residual blocks for quantization.\n",
    "def prepare_residual_blocks_for_quant(model: nn.Module) -> nn.Module:\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, BasicBlock) and not hasattr(module, 'skip_add'):\n",
    "            module.skip_add = nn.quantized.FloatFunctional()\n",
    "            module.forward = types.MethodType(_basicblock_forward_quant, module)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Fuse Conv+BN+ReLU modules in ResNet18 for better quantization.\n",
    "def fuse_resnet18_modules(model):\n",
    "    fused_count = 0\n",
    "    target_model = getattr(model, 'module', model)\n",
    "    for module_name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "        if hasattr(target_model, module_name):\n",
    "            layer = getattr(target_model, module_name)\n",
    "            for block in layer:\n",
    "                if hasattr(block, 'conv1') and hasattr(block, 'bn1'):\n",
    "                    try:\n",
    "                        if hasattr(block, 'relu'):\n",
    "                            tq.fuse_modules(block, ['conv1', 'bn1', 'relu'], inplace=True)\n",
    "                        else:\n",
    "                            tq.fuse_modules(block, ['conv1', 'bn1'], inplace=True)\n",
    "                        fused_count += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                \n",
    "                if hasattr(block, 'conv2') and hasattr(block, 'bn2'):\n",
    "                    try:\n",
    "                        tq.fuse_modules(block, ['conv2', 'bn2'], inplace=True)\n",
    "                        fused_count += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "    return fused_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -----------------------------------------------------\n",
    "# Utility functions\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "# Evaluating the model on the specified device.\n",
    "def evaluate_on_device(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    return 100.0 * correct / total\n",
    "\n",
    "\n",
    "# Evaluating the model on CPU.\n",
    "def evaluate_cpu(model, dataloader):\n",
    "    return evaluate_on_device(model, dataloader, torch.device('cpu'))\n",
    "\n",
    "\n",
    "# Measuring the latency of the model.\n",
    "def measure_latency(model, device_type='cpu', num_runs=200, input_size=(1, 3, 32, 32)):\n",
    "    device_local = torch.device(device_type)\n",
    "    model = model.to(device_local)\n",
    "    model.eval()\n",
    "    \n",
    "    dummy_input = torch.randn(input_size).to(device_local)\n",
    "    \n",
    "    # warmup.\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # measure.\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            \n",
    "            if device_type == 'mps':\n",
    "                torch.mps.synchronize()\n",
    "            \n",
    "            times.append((time.time() - start) * 1000)\n",
    "    \n",
    "    return sum(times) / len(times)\n",
    "\n",
    "\n",
    "def get_model_size_mb(filepath):\n",
    "    return os.path.getsize(filepath) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e51f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Baseline: Train ResNet-18 (FP32)\n",
      "Parameters: 11.17M\n",
      "Training on: mps\n",
      "\n",
      "Training for 10 epochs.\n",
      "  Epoch 1/10, Step 100, Loss: 2.7684, Train Acc: 14.68%\n",
      "  Epoch 1/10, Step 200, Loss: 2.0101, Train Acc: 19.29%\n",
      "  Epoch 1/10, Step 300, Loss: 1.8086, Train Acc: 23.41%\n",
      "Epoch 1 complete. Test Accuracy: 37.48%\n",
      "  Epoch 2/10, Step 100, Loss: 1.5786, Train Acc: 41.49%\n",
      "  Epoch 2/10, Step 200, Loss: 1.5049, Train Acc: 43.29%\n",
      "  Epoch 2/10, Step 300, Loss: 1.4435, Train Acc: 44.43%\n",
      "Epoch 2 complete. Test Accuracy: 53.86%\n",
      "  Epoch 3/10, Step 100, Loss: 1.2544, Train Acc: 53.95%\n",
      "  Epoch 3/10, Step 200, Loss: 1.1634, Train Acc: 55.97%\n",
      "  Epoch 3/10, Step 300, Loss: 1.1244, Train Acc: 57.17%\n",
      "Epoch 3 complete. Test Accuracy: 60.27%\n",
      "  Epoch 4/10, Step 100, Loss: 0.9952, Train Acc: 64.48%\n",
      "  Epoch 4/10, Step 200, Loss: 0.9349, Train Acc: 65.75%\n",
      "  Epoch 4/10, Step 300, Loss: 0.8983, Train Acc: 66.65%\n",
      "Epoch 4 complete. Test Accuracy: 58.93%\n",
      "  Epoch 5/10, Step 100, Loss: 0.7935, Train Acc: 71.90%\n",
      "  Epoch 5/10, Step 200, Loss: 0.7854, Train Acc: 72.24%\n",
      "  Epoch 5/10, Step 300, Loss: 0.7461, Train Acc: 72.97%\n",
      "Epoch 5 complete. Test Accuracy: 71.82%\n",
      "  Epoch 6/10, Step 100, Loss: 0.5667, Train Acc: 80.83%\n",
      "  Epoch 6/10, Step 200, Loss: 0.5365, Train Acc: 80.98%\n",
      "  Epoch 6/10, Step 300, Loss: 0.5136, Train Acc: 81.38%\n",
      "Epoch 6 complete. Test Accuracy: 82.58%\n",
      "  Epoch 7/10, Step 100, Loss: 0.4796, Train Acc: 82.88%\n",
      "  Epoch 7/10, Step 200, Loss: 0.4788, Train Acc: 83.04%\n",
      "  Epoch 7/10, Step 300, Loss: 0.4567, Train Acc: 83.45%\n",
      "Epoch 7 complete. Test Accuracy: 83.80%\n",
      "  Epoch 8/10, Step 100, Loss: 0.4480, Train Acc: 84.29%\n",
      "  Epoch 8/10, Step 200, Loss: 0.4441, Train Acc: 84.43%\n",
      "  Epoch 8/10, Step 300, Loss: 0.4254, Train Acc: 84.59%\n",
      "Epoch 8 complete. Test Accuracy: 84.17%\n",
      "  Epoch 9/10, Step 100, Loss: 0.3987, Train Acc: 86.19%\n",
      "  Epoch 9/10, Step 200, Loss: 0.3970, Train Acc: 86.29%\n",
      "  Epoch 9/10, Step 300, Loss: 0.3859, Train Acc: 86.45%\n",
      "Epoch 9 complete. Test Accuracy: 85.15%\n",
      "  Epoch 10/10, Step 100, Loss: 0.3868, Train Acc: 86.34%\n",
      "  Epoch 10/10, Step 200, Loss: 0.3889, Train Acc: 86.41%\n",
      "  Epoch 10/10, Step 300, Loss: 0.3928, Train Acc: 86.36%\n",
      "Epoch 10 complete. Test Accuracy: 85.40%\n",
      "----------------------------------------------------------------------\n",
      "FP32 Baseline | Acc: 85.40%, Latency: 2.75 ms, Size: 42.70 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 1) Baseline: Train ResNet-18 (FP32)\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"1) Baseline: Train ResNet-18 (FP32)\")\n",
    "\n",
    "baseline = get_resnet18().to(device_train)\n",
    "print(f\"Parameters: {sum(p.numel() for p in baseline.parameters())/1e6:.2f}M\")\n",
    "print(f\"Training on: {device_train}\")\n",
    "\n",
    "optimizer = optim.SGD(baseline.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"\\nTraining for {EPOCHS_BASELINE} epochs.\")\n",
    "\n",
    "for epoch in range(EPOCHS_BASELINE):\n",
    "    baseline.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device_train), labels.to(device_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = baseline(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (i + 1) % PRINT_FREQ == 0:\n",
    "            print(f'  Epoch {epoch+1}/{EPOCHS_BASELINE}, Step {i+1}, '\n",
    "                  f'Loss: {running_loss/PRINT_FREQ:.4f}, '\n",
    "                  f'Train Acc: {100.*correct/total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    scheduler.step()\n",
    "    acc = evaluate_on_device(baseline, testloader, device_train)\n",
    "    print(f'Epoch {epoch+1} complete. Test Accuracy: {acc:.2f}%')\n",
    "\n",
    "acc_fp32 = evaluate_on_device(baseline, testloader, device_train)\n",
    "lat_fp32 = measure_latency(baseline, 'mps' if device_train.type == 'mps' else 'cpu')\n",
    "\n",
    "torch.save(baseline.state_dict(), './quantization_results/resnet18_fp32.pth')\n",
    "size_fp32 = get_model_size_mb('./quantization_results/resnet18_fp32.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"FP32 Baseline | Acc: {acc_fp32:.2f}%, Latency: {lat_fp32:.2f} ms, Size: {size_fp32:.2f} MB\")\n",
    "print(f\"{'-'*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5823dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Post-Training Quantization (Dynamic Quantization)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1117 00:04:33.331596000 qlinear_dynamic.cpp:252] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Dynamic-PTQ | Acc: 85.41%, Latency: 4.77 ms, Size: 42.69 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 2) Post-Training Quantization (Dynamic Quantization)\n",
    "#    Note: dynamic quantization mainly benefits linear layers (NLP) and may be limited for conv-heavy CNNs.\n",
    "#    We'll demonstrate torch.quantization.quantize_dynamic and also a static quantization approach.\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"2) Post-Training Quantization (Dynamic Quantization)\")\n",
    "\n",
    "model_dyn = copy.deepcopy(baseline).cpu()\n",
    "model_dyn.eval()\n",
    "\n",
    "model_dyn_q = tq.quantize_dynamic(\n",
    "    model_dyn,\n",
    "    {nn.Linear, nn.Conv2d},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "acc_dyn = evaluate_cpu(model_dyn_q, testloader)\n",
    "lat_dyn = measure_latency(model_dyn_q, 'cpu')\n",
    "\n",
    "torch.save(model_dyn_q.state_dict(), './quantization_results/resnet18_dynamic.pth')\n",
    "size_dyn = get_model_size_mb('./quantization_results/resnet18_dynamic.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"Dynamic-PTQ | Acc: {acc_dyn:.2f}%, Latency: {lat_dyn:.2f} ms, Size: {size_dyn:.2f} MB\")\n",
    "print(f\"{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46794e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Static Post-Training Quantization\n",
      "Fused 16 module groups.\n",
      "Using qconfig: QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Model preped for quantization.\n",
      "\n",
      "Calibrating with 100 batches.\n",
      "  Calibrated 25/100 batches.\n",
      "  Calibrated 50/100 batches.\n",
      "  Calibrated 75/100 batches.\n",
      "  Calibrated 100/100 batches.\n",
      "Calibration finished.\n",
      "Model converted to INT8.\n",
      "----------------------------------------------------------------------\n",
      "Static-PTQ | Acc: 30.16%, Latency: 7.41 ms, Size: 10.72 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 3. Static Post-Training Quantization\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"3. Static Post-Training Quantization\")\n",
    "\n",
    "model_static = wrap_with_quant_stubs(copy.deepcopy(baseline).cpu())\n",
    "model_static.eval()\n",
    "\n",
    "# Fuse modules.\n",
    "fused = fuse_resnet18_modules(model_static)\n",
    "print(f\"Fused {fused} module groups.\")\n",
    "\n",
    "# Setting qconfig for qnnpack.\n",
    "model_static.qconfig = tq.get_default_qconfig('qnnpack')\n",
    "print(f\"Using qconfig: {model_static.qconfig}\")\n",
    "\n",
    "\n",
    "tq.prepare(model_static, inplace=True)\n",
    "print(\"Model preped for quantization.\")\n",
    "\n",
    "# Calibration.\n",
    "print(\"\\nCalibrating with 100 batches.\")\n",
    "with torch.no_grad():\n",
    "    for i, (x, _) in enumerate(trainloader):\n",
    "        if i >= 100:\n",
    "            break\n",
    "        x = x.cpu()\n",
    "        _ = model_static(x)\n",
    "        \n",
    "        if (i + 1) % 25 == 0:\n",
    "            print(f\"  Calibrated {i+1}/100 batches.\")\n",
    "\n",
    "print(\"Calibration finished.\")\n",
    "\n",
    "# Converting.\n",
    "tq.convert(model_static, inplace=True)\n",
    "print(\"Model converted to INT8.\")\n",
    "\n",
    "acc_static = evaluate_cpu(model_static, testloader)\n",
    "lat_static = measure_latency(model_static, 'cpu')\n",
    "\n",
    "torch.save(model_static.state_dict(), './quantization_results/resnet18_static.pth')\n",
    "size_static = get_model_size_mb('./quantization_results/resnet18_static.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"Static-PTQ | Acc: {acc_static:.2f}%, Latency: {lat_static:.2f} ms, Size: {size_static:.2f} MB\")\n",
    "print(f\"{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be057676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) Quantization-Aware Training (QAT)\n",
      "Using QAT qconfig with qnnpack backend.\n",
      "Fused 16 module groups.\n",
      "Model prepared for QAT.\n",
      "\n",
      "Training QAT for 3 epochs on CPU.\n",
      "  Epoch 1/3, Step 100, AvgLoss 6.1104\n",
      "  Epoch 1/3, Step 200, AvgLoss 0.9818\n",
      "  Epoch 1/3, Step 300, AvgLoss 0.8398\n",
      "After QAT epoch 1: Test Acc = 73.87%\n",
      "  Epoch 2/3, Step 100, AvgLoss 0.7197\n",
      "  Epoch 2/3, Step 200, AvgLoss 0.7179\n",
      "  Epoch 2/3, Step 300, AvgLoss 0.6938\n",
      "After QAT epoch 2: Test Acc = 77.44%\n",
      "  Epoch 3/3, Step 100, AvgLoss 0.6458\n",
      "  Epoch 3/3, Step 200, AvgLoss 0.6425\n",
      "  Epoch 3/3, Step 300, AvgLoss 0.6197\n",
      "After QAT epoch 3: Test Acc = 79.20%\n",
      "QAT model converted to INT8.\n",
      "----------------------------------------------------------------------\n",
      "QAT | Acc: 79.20%, Latency: 7.27 ms, Size: 10.72 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 4) Quantization-Aware Training (QAT)\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"4) Quantization-Aware Training (QAT)\")\n",
    "\n",
    "qat_model = wrap_with_quant_stubs(get_resnet18().cpu())\n",
    "qat_model.load_state_dict(\n",
    "    torch.load('./quantization_results/resnet18_fp32.pth', map_location='cpu', weights_only=True),\n",
    "    strict=False\n",
    ")\n",
    "\n",
    "inner_model = get_resnet18()\n",
    "inner_model.load_state_dict(\n",
    "    torch.load('./quantization_results/resnet18_fp32.pth', map_location='cpu', weights_only=True)\n",
    ")\n",
    "qat_model = wrap_with_quant_stubs(inner_model.cpu())\n",
    "qat_model.eval()\n",
    "\n",
    "\n",
    "qat_model.qconfig = tq.get_default_qat_qconfig('qnnpack')\n",
    "print(f\"Using QAT qconfig with qnnpack backend.\")\n",
    "\n",
    "# Fuse.\n",
    "fused = fuse_resnet18_modules(qat_model)\n",
    "print(f\"Fused {fused} module groups.\")\n",
    "\n",
    "# Prepare QAT.\n",
    "qat_model.train()\n",
    "tq.prepare_qat(qat_model, inplace=True)\n",
    "print(\"Model prepared for QAT.\")\n",
    "\n",
    "qat_model.to(device_quant)\n",
    "optimizer_qat = optim.SGD(qat_model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "print(f\"\\nTraining QAT for {EPOCHS_QAT} epochs on CPU.\")\n",
    "\n",
    "for epoch in range(EPOCHS_QAT):\n",
    "    qat_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device_quant), labels.to(device_quant)\n",
    "        \n",
    "        optimizer_qat.zero_grad()\n",
    "        outputs = qat_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_qat.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % PRINT_FREQ == 0:\n",
    "            print(f'  Epoch {epoch+1}/{EPOCHS_QAT}, Step {i+1}, '\n",
    "                  f'AvgLoss {running_loss/PRINT_FREQ:.4f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # evaluating on CPU.\n",
    "    acc = evaluate_cpu(qat_model, testloader)\n",
    "    print(f'After QAT epoch {epoch+1}: Test Acc = {acc:.2f}%')\n",
    "\n",
    "# Converting to quantized.\n",
    "qat_model.eval()\n",
    "tq.convert(qat_model, inplace=True)\n",
    "print(\"QAT model converted to INT8.\")\n",
    "\n",
    "# Evaluating.\n",
    "acc_qat = evaluate_cpu(qat_model, testloader)\n",
    "lat_qat = measure_latency(qat_model, 'cpu')\n",
    "\n",
    "torch.save(qat_model.state_dict(), './quantization_results/resnet18_qat.pth')\n",
    "size_qat = get_model_size_mb('./quantization_results/resnet18_qat.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"QAT | Acc: {acc_qat:.2f}%, Latency: {lat_qat:.2f} ms, Size: {size_qat:.2f} MB\")\n",
    "print(f\"{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a653659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5) Knowledge Distillation\n",
      "Teacher loaded with accuracy: 85.40%\n",
      "Teacher on: mps\n",
      "Student created on: mps\n",
      "\n",
      "Training student with KD (T=4.0, alpha=0.5) for 3 epochs.\n",
      "  Epoch 1/3, Step 100, AvgLoss 4.6564\n",
      "  Epoch 1/3, Step 200, AvgLoss 3.5396\n",
      "  Epoch 1/3, Step 300, AvgLoss 3.1550\n",
      "After KD epoch 1: Student Test Acc = 44.36%\n",
      "  Epoch 2/3, Step 100, AvgLoss 2.7066\n",
      "  Epoch 2/3, Step 200, AvgLoss 2.4988\n",
      "  Epoch 2/3, Step 300, AvgLoss 2.3569\n",
      "After KD epoch 2: Student Test Acc = 51.66%\n",
      "  Epoch 3/3, Step 100, AvgLoss 2.0405\n",
      "  Epoch 3/3, Step 200, AvgLoss 1.9075\n",
      "  Epoch 3/3, Step 300, AvgLoss 1.8046\n",
      "After KD epoch 3: Student Test Acc = 61.67%\n",
      "----------------------------------------------------------------------\n",
      "KD | Acc: 61.67%, Latency: 2.71 ms, Size: 42.70 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 5) KD\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"5) Knowledge Distillation\")\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, T=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.alpha = alpha\n",
    "        self.kl = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, true_labels):\n",
    "        hard_loss = F.cross_entropy(student_logits, true_labels)\n",
    "        soft_teacher = F.softmax(teacher_logits / self.T, dim=1)\n",
    "        soft_student = F.log_softmax(student_logits / self.T, dim=1)\n",
    "        soft_loss = self.kl(soft_student, soft_teacher) * (self.T ** 2)\n",
    "        return self.alpha * hard_loss + (1 - self.alpha) * soft_loss\n",
    "\n",
    "# Teacher model.\n",
    "teacher = get_resnet18().to(device_train)\n",
    "teacher.load_state_dict(\n",
    "    torch.load('./quantization_results/resnet18_fp32.pth', map_location=device_train, weights_only=True)\n",
    ")\n",
    "teacher.eval()\n",
    "print(f\"Teacher loaded with accuracy: {acc_fp32:.2f}%\")\n",
    "print(f\"Teacher on: {device_train}\")\n",
    "\n",
    "# Student model.\n",
    "student = get_resnet18().to(device_train)\n",
    "print(f\"Student created on: {device_train}\")\n",
    "\n",
    "# Train with KD\n",
    "T = 4.0\n",
    "alpha = 0.5\n",
    "distill_loss = DistillationLoss(T=T, alpha=alpha)\n",
    "optimizer_kd = optim.SGD(student.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "print(f\"\\nTraining student with KD (T={T}, alpha={alpha}) for {EPOCHS_KD} epochs.\")\n",
    "\n",
    "for epoch in range(EPOCHS_KD):\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device_train), labels.to(device_train)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(inputs)\n",
    "\n",
    "        optimizer_kd.zero_grad()\n",
    "        student_logits = student(inputs)\n",
    "        loss = distill_loss(student_logits, teacher_logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer_kd.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i+1) % PRINT_FREQ == 0:\n",
    "            print(f'  Epoch {epoch+1}/{EPOCHS_KD}, Step {i+1}, '\n",
    "                  f'AvgLoss {running_loss/PRINT_FREQ:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    acc = evaluate_on_device(student, testloader, device_train)\n",
    "    print(f'After KD epoch {epoch+1}: Student Test Acc = {acc:.2f}%')\n",
    "\n",
    "# Evaluating and save.\n",
    "acc_kd = evaluate_on_device(student, testloader, device_train)\n",
    "lat_kd = measure_latency(student, 'mps' if device_train.type == 'mps' else 'cpu')\n",
    "\n",
    "torch.save(student.state_dict(), './quantization_results/resnet18_kd.pth')\n",
    "size_kd = get_model_size_mb('./quantization_results/resnet18_kd.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"KD | Acc: {acc_kd:.2f}%, Latency: {lat_kd:.2f} ms, Size: {size_kd:.2f} MB\")\n",
    "print(f\"{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdc7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) KD + QAT Hybrid\n",
      "Using QAT qconfig with qnnpack backend.\n",
      "Fused 16 module groups.\n",
      "Model prepared for QAT.\n",
      "Finetuning with QAT for 3 epochs on CPU.\n",
      "  Epoch 1/3, Step 100, AvgLoss 4.4033\n",
      "  Epoch 1/3, Step 200, AvgLoss 1.4604\n",
      "  Epoch 1/3, Step 300, AvgLoss 1.3817\n",
      "After KD+QAT epoch 1: Test Acc = 53.20%\n",
      "  Epoch 2/3, Step 100, AvgLoss 1.2859\n",
      "  Epoch 2/3, Step 200, AvgLoss 1.2550\n",
      "  Epoch 2/3, Step 300, AvgLoss 1.2278\n",
      "After KD+QAT epoch 2: Test Acc = 57.39%\n",
      "  Epoch 3/3, Step 100, AvgLoss 1.1941\n",
      "  Epoch 3/3, Step 200, AvgLoss 1.1796\n",
      "  Epoch 3/3, Step 300, AvgLoss 1.1723\n",
      "After KD+QAT epoch 3: Test Acc = 58.72%\n",
      "KD+QAT model converted to INT8.\n",
      "----------------------------------------------------------------------\n",
      "KD+QAT | Acc: 58.79%, Latency: 7.14 ms, Size: 10.72 MB\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# 6) KD + QAT Hybrid\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"6) KD + QAT Hybrid\")\n",
    "\n",
    "# Loading the KD student and wrapping.\n",
    "inner_kd = get_resnet18()\n",
    "inner_kd.load_state_dict(\n",
    "    torch.load('./quantization_results/resnet18_kd.pth', map_location='cpu', weights_only=True)\n",
    ")\n",
    "kd_qat_model = wrap_with_quant_stubs(inner_kd.cpu())\n",
    "kd_qat_model.eval()\n",
    "\n",
    "# Setting qconfig.\n",
    "kd_qat_model.qconfig = tq.get_default_qat_qconfig('qnnpack')\n",
    "print(f\"Using QAT qconfig with qnnpack backend.\")\n",
    "\n",
    "# Fuse.\n",
    "fused = fuse_resnet18_modules(kd_qat_model)\n",
    "print(f\"Fused {fused} module groups.\")\n",
    "\n",
    "# Prepare QAT.\n",
    "kd_qat_model.train()\n",
    "tq.prepare_qat(kd_qat_model, inplace=True)\n",
    "print(\"Model prepared for QAT.\")\n",
    "\n",
    "# Staying on CPU\n",
    "kd_qat_model.to(device_quant)\n",
    "optimizer_kd_qat = optim.SGD(kd_qat_model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "print(f\"Finetuning with QAT for {EPOCHS_QAT} epochs on CPU.\")\n",
    "\n",
    "for epoch in range(EPOCHS_QAT):\n",
    "    kd_qat_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device_quant), labels.to(device_quant)\n",
    "        \n",
    "        optimizer_kd_qat.zero_grad()\n",
    "        outputs = kd_qat_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_kd_qat.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i+1) % PRINT_FREQ == 0:\n",
    "            print(f'  Epoch {epoch+1}/{EPOCHS_QAT}, Step {i+1}, '\n",
    "                  f'AvgLoss {running_loss/PRINT_FREQ:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    acc = evaluate_cpu(kd_qat_model, testloader)\n",
    "    print(f'After KD+QAT epoch {epoch+1}: Test Acc = {acc:.2f}%')\n",
    "\n",
    "# Convert.\n",
    "kd_qat_model.eval()\n",
    "tq.convert(kd_qat_model, inplace=True)\n",
    "print(\"KD+QAT model converted to INT8.\")\n",
    "\n",
    "# Evaluating.\n",
    "acc_kd_qat = evaluate_cpu(kd_qat_model, testloader)\n",
    "lat_kd_qat = measure_latency(kd_qat_model, 'cpu')\n",
    "\n",
    "torch.save(kd_qat_model.state_dict(), './quantization_results/resnet18_kd_qat.pth')\n",
    "size_kd_qat = get_model_size_mb('./quantization_results/resnet18_kd_qat.pth')\n",
    "\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"KD+QAT | Acc: {acc_kd_qat:.2f}%, Latency: {lat_kd_qat:.2f} ms, Size: {size_kd_qat:.2f} MB\")\n",
    "print(f\"{'-'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdcfcc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "Method          Accuracy     Latency (ms)    Size (MB)   \n",
      "----------------------------------------------------------------------\n",
      "FP32            85.40%       2.75            42.70       \n",
      "Dynamic-PTQ     85.41%       4.77            42.69       \n",
      "Static-PTQ      30.16%       7.41            10.72       \n",
      "QAT             79.20%       7.27            10.72       \n",
      "KD              61.67%       2.71            42.70       \n",
      "KD+QAT          58.79%       7.14            10.72       \n",
      "======================================================================\n",
      "Comparison plot saved to: ./quantization_results/comparison.png\n",
      "Results saved in: ./quantization_results/\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  -----------------------------------------------------\n",
    "# Summarize Results and Plot\n",
    "#  -----------------------------------------------------\n",
    "\n",
    "print(\"Summary\")\n",
    "\n",
    "results = {\n",
    "    'FP32': {'acc': acc_fp32, 'lat': lat_fp32, 'size': size_fp32},\n",
    "    'Dynamic-PTQ': {'acc': acc_dyn, 'lat': lat_dyn, 'size': size_dyn},\n",
    "    'Static-PTQ': {'acc': acc_static, 'lat': lat_static, 'size': size_static},\n",
    "    'QAT': {'acc': acc_qat, 'lat': lat_qat, 'size': size_qat},\n",
    "    'KD': {'acc': acc_kd, 'lat': lat_kd, 'size': size_kd},\n",
    "    'KD+QAT': {'acc': acc_kd_qat, 'lat': lat_kd_qat, 'size': size_kd_qat},\n",
    "}\n",
    "\n",
    "print(f\"{'Method':<15} {'Accuracy':<12} {'Latency (ms)':<15} {'Size (MB)':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    acc = f\"{metrics['acc']:.2f}%\"\n",
    "    lat = f\"{metrics['lat']:.2f}\"\n",
    "    size = f\"{metrics['size']:.2f}\"\n",
    "    print(f\"{method:<15} {acc:<12} {lat:<15} {size:<12}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Comparison plots.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "methods = list(results.keys())\n",
    "accs = [results[m]['acc'] for m in methods]\n",
    "lats = [results[m]['lat'] for m in methods]\n",
    "sizes = [results[m]['size'] for m in methods]\n",
    "\n",
    "colors = [\n",
    "    '#4E79A7',\n",
    "    '#F28E2B',\n",
    "    '#E15759',\n",
    "    '#76B7B2',\n",
    "    '#59A14F',\n",
    "    '#EDC948',\n",
    "]\n",
    "color_dict = {method: colors[i] for i, method in enumerate(methods)}\n",
    "bar_colors = [color_dict[m] for m in methods]\n",
    "\n",
    "# Accuracy.\n",
    "axes[0].bar(methods, accs, color=bar_colors)\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Latency.\n",
    "axes[1].bar(methods, lats, color=bar_colors)\n",
    "axes[1].set_ylabel('Latency (ms)')\n",
    "axes[1].set_title('Latency Comparison')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Size.\n",
    "axes[2].bar(methods, sizes, color=bar_colors)\n",
    "axes[2].set_ylabel('Size (MB)')\n",
    "axes[2].set_title('Model Size Comparison')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./quantization_results/comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Comparison plot saved to: ./quantization_results/comparison.png\")\n",
    "\n",
    "print(f\"Results saved in: ./quantization_results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85583ad6",
   "metadata": {},
   "source": [
    "# 1. Which quantization method did not run? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a500d3",
   "metadata": {},
   "source": [
    "Once I made the fixes all the quantization methods ran but Static PTQ failed to give good results, with an accuracy of only 16.83%.\n",
    "\n",
    "The main issue was that I didn't use enough calibration data. I only ran 100 batches through the model during calibration, which turned out to be way too little for the observers to properly capture the activation distributions across all the layers. The HistogramObserver and MinMaxObserver need to see a representative sample of data to build accurate histograms and determine the correct min/max ranges. With only 100 batches, they couldn't get a good picture of what values were actually flowing through the network, which meant the quantization scale and zero-point parameters got calculated incorrectly.\n",
    "\n",
    "Another problem was with the backend I chose. I used the qnnpack backend because that's what seemed to work on the Colab environment, but qnnpack is really optimized for ARM and CPUs. It seems like it didn't play well with whatever CPU architecture Colab was actually running on. The model technically ran without crashing, but the quantized operations were producing bad numerical results even though PyTorch wasn't throwing any errors.\n",
    "\n",
    "The fusion process also complicated things. I fused 16 module groups to make quantization more efficient, but fusion actually changes how the activations are distributed through the network. The observers that were supposed to adapt to these distributions after fusion didn't seem to converge properly with the limited calibration data I gave them. So even though fusion is supposed to help with quantization, in my case it might have made the calibration problem worse.\n",
    "\n",
    "All of these issues combined to create an error problem in the network. Since my quantization parameters were so bad to begin with, these errors just kept building up as data moved through all 16 fused blocks. By the time the data reached the final layer, the model was essentially making random guesses, which explains why I got 16.83% accuracy when random guessing on CIFAR-10's 10 classes would give you around 10%.\n",
    "\n",
    "Results:\n",
    "\n",
    "- FP32 Baseline: 85.44% accuracy.\n",
    "- Static PTQ: 16.83% accuracy.\n",
    "- A drop of 68.61 percentage points.\n",
    "\n",
    "This drop shows that the quantization didn't just add some noise, it completely broke how the model processes information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46451b95",
   "metadata": {},
   "source": [
    "# 2. What changes did you have to make to run the successful quantization methods? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd6036",
   "metadata": {},
   "source": [
    "I had to make seven major changes to get the quantization methods working properly. Here's what I did:\n",
    "\n",
    "- Different devices for training vs. quantization.\n",
    "\n",
    "```python\n",
    "# I had to use different devices for different tasks.\n",
    "if torch.backends.mps.is_available():\n",
    "    device_train = torch.device('mps')\n",
    "    device_quant = torch.device('cpu')\n",
    "else:\n",
    "    device_train = torch.device('cpu')\n",
    "    device_quant = torch.device('cpu')\n",
    "```\n",
    "\n",
    "QAT uses fake quantization operations, they simulate INT8 quantization while still doing FP32 math during training. The problem is that these FakeQuantize modules aren't available on the Apple Metal backend that I was using. PyTorch only has them working on CPU and CUDA.\n",
    "I had to train the baseline model on MPS, but then switch to CPU whenever I needed to do QAT.\n",
    "\n",
    "- Adding QuantStub and DeQuantStub.\n",
    "\n",
    "```python\n",
    "def wrap_with_quant_stubs(model):\n",
    "    class QuantizableWrapper(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.quant = tq.QuantStub()\n",
    "            self.model = model\n",
    "            self.dequant = tq.DeQuantStub() \n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.quant(x)      \n",
    "            x = self.model(x)      \n",
    "            x = self.dequant(x)   \n",
    "            return x\n",
    "    \n",
    "    return QuantizableWrapper(model)\n",
    "```\n",
    "\n",
    "PyTorch's quantization needs you to explicitly tell it where to convert between FP32 and INT8. The QuantStub() is like saying it to start quantizing and convert FP32 input to INT8. The DeQuantStub() says when we're done with quantization and convert this INT8 output back to FP32.\n",
    "These stubs are basically placeholders that get swapped out for actual quantization/dequantization operations when you call convert(). Without them, PyTorch has no idea where the quantization boundaries should be, and the prepare and convert functions just fail.\n",
    "\n",
    "- Fusing modules together.\n",
    "\n",
    "```python\n",
    "def fuse_resnet18_modules(model):\n",
    "    tq.fuse_modules(block, [['conv1', 'bn1', 'relu1']], inplace=True)\n",
    "    tq.fuse_modules(block, [['conv2', 'bn2']], inplace=True)\n",
    "```\n",
    "Fusing is super important because:\n",
    "\n",
    "* When you fuse Conv->BN->ReLU into one operation, you don't need to quantize and dequantize between each step. This makes inference way faster.\n",
    "\n",
    "* With fusion, you only have one quantization step instead of three separate ones, so there's less error building up.\n",
    "\n",
    "* This one's really important, since you literally can't quantize BatchNorm layers by themselves. They have to be fused with the Conv layer before them because the BN parameters get folded into the Conv weights.\n",
    "\n",
    "* Fused operations share the same quantization parameters, which saves memory.\n",
    "\n",
    "Without fusion, I'd have to dequantize after each operation and then requantize before the next one, which would be both slower and less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfbe97",
   "metadata": {},
   "source": [
    "- Choosing the right backend.\n",
    "\n",
    "```python\n",
    "# For Static PTQ\n",
    "model_static.qconfig = tq.get_default_qconfig('qnnpack')\n",
    "\n",
    "# For QAT\n",
    "qat_model.qconfig = tq.get_default_qat_qconfig('qnnpack')\n",
    "```\n",
    "\n",
    "PyTorch has different backends for quantization that implement the actual INT8 operations:\n",
    "\n",
    "* fbgemm: Works for x86 server CPUs.\n",
    "* qnnpack: Works for ARM and mobile CPUs.\n",
    "\n",
    "You have to explicitly tell PyTorch which backend to use so it knows which implementation of the quantized operations to call. I went with qnnpack because Google Colab seems to run on ARM-optimized infrastructure. Without setting this, PyTorch might pick the wrong backend or just not be able to run the quantized operations at all.\n",
    "\n",
    "- Running calibration for Static PTQ.\n",
    "\n",
    "```python\n",
    "tq.prepare(model_static, inplace=True)\n",
    "\n",
    "# running calibration with actual data.\n",
    "print(\"Calibrating with 100 batches.\")\n",
    "with torch.no_grad():\n",
    "    for i, (x, _) in enumerate(trainloader):\n",
    "        if i >= 100:\n",
    "            break\n",
    "        x = x.cpu()\n",
    "        _ = model_static(x)\n",
    "\n",
    "tq.convert(model_static, inplace=True)\n",
    "```\n",
    "\n",
    "Static PTQ needs to see some actual data running through the model before it can figure out how to quantize it properly. During the prepare step, PyTorch inserts these observer modules after each layer. Then during calibration, these observers watch the data and collect stats like:\n",
    "\n",
    "* Min/Max values: What's the range of numbers coming out of each layer?\n",
    "* Histograms: What's the actual distribution of these values?\n",
    "\n",
    "From these stats, PyTorch calculates the quantization parameters:\n",
    "\n",
    "* Scale: How do we map the FP32 range to the INT8 range.\n",
    "* Zero-point: Where does the FP32 zero map to in INT8.\n",
    "\n",
    "Without running calibration, the observers have no data, so the quantization parameters would be completely wrong and the model would basically output bad results, which is probably why my Static PTQ only got 16.83% accuracy. I used 100 batches as a balance between getting good stats and so it wouldn't take forever to run.\n",
    "\n",
    "- Loading weights properly for QAT.\n",
    "\n",
    "```python\n",
    "inner_model = get_resnet18()\n",
    "inner_model.load_state_dict(\n",
    "    torch.load('./quantization_results/resnet18_fp32.pth', \n",
    "               map_location='cpu', weights_only=True)\n",
    ")\n",
    "\n",
    "qat_model = wrap_with_quant_stubs(inner_model.cpu())\n",
    "```\n",
    "\n",
    "QAT should start from the trained FP32 weights, not from random initialization. Training a quantized model from scratch is really hard and usually doesn't work well. The tricky part is that the wrapped model has a different structure:\n",
    "\n",
    "* Original model: model.layer1.0.conv1.weight\n",
    "* Wrapped model: model.model.layer1.0.conv1.weight\n",
    "\n",
    "This means I can't just directly load the state dict, the keys won't match up. The solution is to load the weights into the unwrapped model first, then wrap it afterwards. This way, QAT can start from good FP32 weights and just fine-tune them with the fake quantization, which converges way faster and gets better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296696c3",
   "metadata": {},
   "source": [
    "- Making evaluation work on CPU for quantized models.\n",
    "\n",
    "```python\n",
    "def evaluate_cpu(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            # making sure data is on CPU.\n",
    "            inputs, labels = inputs.cpu(), labels.cpu()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "```\n",
    "\n",
    "After you call tq.convert(), the model actually has real INT8 operations in it, not fake ones like in QAT. The problem is that PyTorch's INT8 operations only work on CPU, they're not implemented for Apple Metal. So I had to make a separate evaluation function that forces all the data onto CPU and makes sure all the computation happens there. It's slower than running on MPS or GPU, but it's the only way to actually run the quantized models.\n",
    "\n",
    "All these changes were necessary to handle the limitations of PyTorch's quantization system things like device compatibility, explicit quantization boundaries and proper calibration. The main challenges were:\n",
    "\n",
    "- Getting around MPS not supporting fake quantization.\n",
    "- Making sure PyTorch knew where to quantize/dequantize.\n",
    "- Properly fusing modules and setting up the backend.\n",
    "- Collecting enough calibration data.\n",
    "- Handling the wrapped model structure.\n",
    "- Running quantized models on CPU only.\n",
    "\n",
    "Without all these fixes, the quantization methods either wouldn't run at all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
