**Model Efficiency (Knowledge Distillation & Quantization)**

This README documents what I ran and learned from the two parts of the assignment:
	•	Part A — Knowledge Distillation: Model-Performance/knowledge_distillation.ipynb
	•	Part B — Quantization: Model-Performance/quantization.py (replicated and tested in HW3_PartB (4).ipynb)

The notes below summarize why each technique is used, what went wrong, how it was fixed, and what I observed when changing key hyperparameters or quantization settings.
